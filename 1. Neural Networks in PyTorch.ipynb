{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Neural Networks in PyTorch:\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Loading Dataset:\n",
    "First up, we need to get our dataset. This is provided through the `torchvision` package. The code below will download the MNIST dataset, then create training and test datasets for us. Don't worry too much about the details here, you'll learn more about this later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /Users/harish3110/.pytorch/MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 9887744/9912422 [00:25<00:00, 460596.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/harish3110/.pytorch/MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /Users/harish3110/.pytorch/MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/28881 [00:00<?, ?it/s]\u001b[A\n",
      " 57%|█████▋    | 16384/28881 [00:00<00:00, 40889.77it/s]\u001b[A\n",
      "32768it [00:00, 33603.28it/s]                           \u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/harish3110/.pytorch/MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /Users/harish3110/.pytorch/MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1648877 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|          | 16384/1648877 [00:01<00:29, 54489.06it/s]\u001b[A\n",
      "  2%|▏         | 40960/1648877 [00:01<00:27, 59442.75it/s]\u001b[A\n",
      "  6%|▌         | 98304/1648877 [00:02<00:25, 60301.07it/s]\u001b[A\n",
      " 10%|▉         | 163840/1648877 [00:02<00:18, 79534.21it/s]\u001b[A\n",
      " 14%|█▍        | 229376/1648877 [00:03<00:15, 94103.52it/s]\u001b[A\n",
      " 18%|█▊        | 294912/1648877 [00:04<00:17, 76183.01it/s]\u001b[A\n",
      " 23%|██▎       | 376832/1648877 [00:04<00:12, 99951.63it/s]\u001b[A\n",
      " 27%|██▋       | 450560/1648877 [00:04<00:10, 116950.62it/s]\u001b[A\n",
      " 32%|███▏      | 532480/1648877 [00:05<00:07, 148128.46it/s]\u001b[A\n",
      " 37%|███▋      | 614400/1648877 [00:05<00:07, 146299.44it/s]\u001b[A\n",
      " 43%|████▎     | 704512/1648877 [00:05<00:05, 182374.41it/s]\u001b[A\n",
      " 49%|████▉     | 811008/1648877 [00:07<00:05, 140834.34it/s]\u001b[A\n",
      " 55%|█████▍    | 901120/1648877 [00:07<00:04, 163850.73it/s]\u001b[A\n",
      " 63%|██████▎   | 1032192/1648877 [00:07<00:03, 178550.41it/s]\u001b[A\n",
      " 71%|███████   | 1163264/1648877 [00:08<00:02, 227566.58it/s]\u001b[A\n",
      " 78%|███████▊  | 1286144/1648877 [00:08<00:01, 279463.20it/s]\u001b[A\n",
      " 86%|████████▌ | 1417216/1648877 [00:08<00:00, 335938.49it/s]\u001b[A\n",
      " 94%|█████████▍| 1556480/1648877 [00:08<00:00, 429416.84it/s]\u001b[A\n",
      " 99%|█████████▉| 1630208/1648877 [00:08<00:00, 487634.66it/s]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/harish3110/.pytorch/MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /Users/harish3110/.pytorch/MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/4542 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "8192it [00:00, 13159.86it/s]            \u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/harish3110/.pytorch/MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9920512it [00:40, 460596.56it/s]                             \n",
      "1654784it [00:23, 487634.66it/s]                             \u001b[A"
     ]
    }
   ],
   "source": [
    "#importing dataset from torchvision package\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the training data loaded into `trainloader` and we make that an iterator with `iter(trainloader)`. Later, we'll use this to loop through the dataset for training, like\n",
    "\n",
    "```python\n",
    "for image, label in trainloader:\n",
    "    ## do things with images and labels\n",
    "```\n",
    "\n",
    "You'll notice I created the `trainloader` with a batch size of 64, and `shuffle=True`. The batch size is the number of images we get in one iteration from the data loader and pass through our network, often called a *batch*. And `shuffle=True` tells it to shuffle the dataset every time we start going through the data loader again. But here I'm just grabbing the first batch so we can check out the data. We can see below that `images` is just a tensor with size `(64, 1, 28, 28)`. So, 64 images per batch, 1 color channel, and 28x28 images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking an image in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x12aca1cf8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label = next(iter(trainloader))\n",
    "plt.imshow(image[0].numpy().squeeze(), cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "print(type(image))\n",
    "print(image.shape)\n",
    "print(label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Neural Network Architecture Parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the activation function: Sigmoid in this case\n",
    "\n",
    "def activation(x):\n",
    "    return 1/(1+torch.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the network architecture parameters\n",
    "\n",
    "# Flatten the input images\n",
    "inputs = image.view(image.shape[0], -1)\n",
    "\n",
    "# Create parameters\n",
    "w1 = torch.randn(784, 256)\n",
    "b1 = torch.randn(256)\n",
    "\n",
    "w2 = torch.randn(256, 10)\n",
    "b2 = torch.randn(10)\n",
    "\n",
    "h = activation(torch.mm(inputs, w1) + b1) #torch.mm is used for matrix multiplication tasks\n",
    "\n",
    "out = torch.mm(h, w2) + b2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have 10 outputs for our network. We want to pass in an image to our network and get out a probability distribution over the classes that tells us the likely class(es) the image belongs to.\n",
    "\n",
    "To calculate this probability distribution, we often use the [**softmax** function](https://en.wikipedia.org/wiki/Softmax_function). Mathematically this looks like\n",
    "\n",
    "$$\n",
    "\\Large \\sigma(x_i) = \\cfrac{e^{x_i}}{\\sum_k^K{e^{x_k}}}\n",
    "$$\n",
    "\n",
    "What this does is squish each input $x_i$ between 0 and 1 and normalizes the values to give you a proper probability distribution where the probabilites sum up to one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10]) \n",
      "\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000])\n"
     ]
    }
   ],
   "source": [
    "def softmax(x):\n",
    "    return torch.exp(x)/torch.sum(torch.exp(x), dim=1).view(-1, 1)\n",
    "\n",
    "probabilities = softmax(out)\n",
    "\n",
    "# Check shape of probabilities\n",
    "print(probabilities.shape, \"\\n\")\n",
    "# Sum of probabilities should equal to 1\n",
    "print(probabilities.sum(dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Building networks with PyTorch:\n",
    "\n",
    "PyTorch provides a module `nn` that makes building networks much simpler. Here I'll show you how to build the same one as above with 784 inputs, 256 hidden units, 10 output units and a softmax output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Inputs to hidden layer linear transformation\n",
    "        self.hidden = nn.Linear(784, 256)\n",
    "        # Output layer, 10 units - one for each digit\n",
    "        self.output = nn.Linear(256, 10)\n",
    "        \n",
    "        # Define sigmoid activation and softmax output \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax(dim=1) #Setting dim=1 in nn.Softmax(dim=1) calculates softmax across the columns.\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Pass the input tensor through each of our operations\n",
    "        x = self.hidden(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.output(x)\n",
    "        x = self.softmax(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here we're inheriting from nn.Module. Combined with super().__init__() this creates a class that tracks the architecture and provides a lot of useful methods and attributes. It is mandatory to inherit from nn.Module when you're creating a class for your network. The name of the class itself can be anything.\n",
    "\n",
    "- \n",
    "```python\n",
    "def forward(self, x):\n",
    "```\n",
    "\n",
    "PyTorch networks created with `nn.Module` must have a `forward` method defined. It takes in a tensor `x` and passes it through the operations you defined in the `__init__` method.\n",
    "\n",
    "```python\n",
    "x = self.hidden(x)\n",
    "x = self.sigmoid(x)\n",
    "x = self.output(x)\n",
    "x = self.softmax(x)\n",
    "```\n",
    "\n",
    "Here the input tensor `x` is passed through each operation a reassigned to `x`. We can see that the input tensor goes through the hidden layer, then a sigmoid function, then the output layer, and finally the softmax function. It doesn't matter what you name the variables here, as long as the inputs and outputs of the operations match the network architecture you want to build. The order in which you define things in the `__init__` method doesn't matter, but you'll need to sequence the operations correctly in the `forward` method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (hidden): Linear(in_features=784, out_features=256, bias=True)\n",
       "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (softmax): Softmax()\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a Network object\n",
    "\n",
    "model = Network()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using torch.nn.functional` module:\n",
    "You can define the network somewhat more concisely and clearly using the `torch.nn.functional` module. This is the most common way you'll see networks defined as many operations are simple element-wise functions. We normally import this module as `F`, `import torch.nn.functional as F`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Inputs to hidden layer linear transformation\n",
    "        self.hidden = nn.Linear(784, 256)\n",
    "        # Output layer, 10 units - one for each digit\n",
    "        self.output = nn.Linear(256, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Hidden layer with sigmoid activation\n",
    "        x = F.sigmoid(self.hidden(x))\n",
    "        # Output layer with softmax activation\n",
    "        x = F.softmax(self.output(x), dim=1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activation functions:\n",
    "\n",
    "So far we've only been looking at the softmax activation, but in general any function can be used as an activation function. The only requirement is that for a network to approximate a non-linear function, the activation functions must be non-linear. Here are a few more examples of common activation functions: Tanh (hyperbolic tangent), and ReLU (rectified linear unit).\n",
    "\n",
    "<img src=\"assets/activation.png\" width=700px>\n",
    "\n",
    "In practice, the ***ReLU function*** is used almost exclusively as the activation function for hidden layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Building another Neural Network:\n",
    "\n",
    "<img src=\"assets/mlp_mnist.png\" width=600px>\n",
    "\n",
    "> **From Image:** Need to create a network with 784 input units, a hidden layer with 128 units and a ReLU activation, then a hidden layer with 64 units and a ReLU activation, and finally an output layer with a softmax activation as shown above. You can use a ReLU activation with the `nn.ReLU` module or `F.relu` function.\n",
    "\n",
    "It's good practice to name your layers by their type of network, for instance 'fc' to represent a fully-connected layer. As you code your solution, use `fc1`, `fc2`, and `fc3` as your layer names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "     def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "    \n",
    "     def forward(self, x):\n",
    "        ''' Forward pass through the network, returns the output logits '''\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Training Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss after one forward pass throuh the above defined network: 2.317699909210205\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(2.3177, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "# Define the loss\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# Get our data\n",
    "images, labels = next(iter(trainloader))\n",
    "# Flatten images\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "# Forward pass, get our log-probabilities\n",
    "logps = model(images)\n",
    "# Calculate the loss with the logps and the labels\n",
    "loss = criterion(logps, labels)\n",
    "\n",
    "print(f\"The loss after one forward pass throuh the above defined network: {loss}\")\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is another loss in PyTorch to note here. Looking at [the documentation for `nn.CrossEntropyLoss`](https://pytorch.org/docs/stable/nn.html#torch.nn.CrossEntropyLoss),\n",
    "​\n",
    "> This criterion combines `nn.LogSoftmax()` and `nn.NLLLoss()` in one single class.\n",
    ">\n",
    "> The input is expected to contain scores for each class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Autograd\n",
    "\n",
    "Now that we know how to calculate a loss, how do we use it to perform backpropagation? Torch provides a module, `autograd`, for automatically calculating the gradients of tensors. We can use it to calculate the gradients of all our parameters with respect to the loss. Autograd works by keeping track of operations performed on tensors, then going backwards through those operations, calculating gradients along the way. To make sure PyTorch keeps track of operations on a tensor and calculates the gradients, you need to set `requires_grad = True` on a tensor. You can do this at creation with the `requires_grad` keyword, or at any time with `x.requires_grad_(True)`.\n",
    "\n",
    "You can turn off gradients for a block of code with the `torch.no_grad()` content:\n",
    "```python\n",
    "x = torch.zeros(1, requires_grad=True)\n",
    ">>> with torch.no_grad():\n",
    "...     y = x * 2\n",
    ">>> y.requires_grad\n",
    "False\n",
    "```\n",
    "\n",
    "Also, you can turn on or off gradients altogether with `torch.set_grad_enabled(True|False)`.\n",
    "\n",
    "The gradients are computed with respect to some variable `z` with `z.backward()`. This does a backward pass through the operations that created `z`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss and Autograd together\n",
    "\n",
    "When we create a network with PyTorch, all of the parameters are initialized with `requires_grad = True`. This means that when we calculate the loss and call `loss.backward()`, the gradients for the parameters are calculated. These gradients are used to update the weights with gradient descent. Below you can see an example of calculating the gradients using a backwards pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "images, labels = next(iter(trainloader))\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "logps = model(images)\n",
    "loss = criterion(logps, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backward pass: \n",
      " None\n",
      "After backward pass: \n",
      " tensor([[-0.0012, -0.0012, -0.0012,  ..., -0.0012, -0.0012, -0.0012],\n",
      "        [-0.0041, -0.0041, -0.0041,  ..., -0.0041, -0.0041, -0.0041],\n",
      "        [-0.0016, -0.0016, -0.0016,  ..., -0.0016, -0.0016, -0.0016],\n",
      "        ...,\n",
      "        [-0.0010, -0.0010, -0.0010,  ..., -0.0010, -0.0010, -0.0010],\n",
      "        [-0.0007, -0.0007, -0.0007,  ..., -0.0007, -0.0007, -0.0007],\n",
      "        [-0.0024, -0.0024, -0.0024,  ..., -0.0024, -0.0024, -0.0024]])\n"
     ]
    }
   ],
   "source": [
    "print('Before backward pass: \\n', model[0].weight.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('After backward pass: \\n', model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizers to update weights:\n",
    "\n",
    "There's one last piece we need to start training, an optimizer that we'll use to update the weights with the gradients. We get these from PyTorch's [`optim` package](https://pytorch.org/docs/stable/optim.html). For example we can use stochastic gradient descent with `optim.SGD`. You can see how to define an optimizer below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "# Optimizers require the parameters to optimize and a learning rate\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Training the Network:\n",
    "Now we know how to use all the individual parts so it's time to see how they work together. Let's consider just one learning step before looping through all the data. The general process with PyTorch:\n",
    "\n",
    "> Steps:\n",
    "> * Make a forward pass through the network \n",
    "> * Use the network output to calculate the loss\n",
    "> * Perform a backward pass through the network with `loss.backward()` to calculate the gradients\n",
    "> * Take a step with the optimizer to update the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weights -  Parameter containing:\n",
      "tensor([[-0.0164,  0.0232, -0.0242,  ...,  0.0014,  0.0196,  0.0070],\n",
      "        [ 0.0271, -0.0080,  0.0136,  ..., -0.0093, -0.0186,  0.0272],\n",
      "        [-0.0044, -0.0123, -0.0298,  ..., -0.0271,  0.0305,  0.0201],\n",
      "        ...,\n",
      "        [ 0.0030,  0.0064, -0.0122,  ..., -0.0331, -0.0209, -0.0108],\n",
      "        [ 0.0254, -0.0187, -0.0191,  ..., -0.0140, -0.0003,  0.0199],\n",
      "        [ 0.0243,  0.0273,  0.0307,  ...,  0.0254, -0.0234, -0.0005]],\n",
      "       requires_grad=True) \n",
      "\n",
      "Gradient - tensor([[-0.0001, -0.0001, -0.0001,  ..., -0.0001, -0.0001, -0.0001],\n",
      "        [-0.0045, -0.0045, -0.0045,  ..., -0.0045, -0.0045, -0.0045],\n",
      "        [-0.0012, -0.0012, -0.0012,  ..., -0.0012, -0.0012, -0.0012],\n",
      "        ...,\n",
      "        [-0.0015, -0.0015, -0.0015,  ..., -0.0015, -0.0015, -0.0015],\n",
      "        [-0.0012, -0.0012, -0.0012,  ..., -0.0012, -0.0012, -0.0012],\n",
      "        [-0.0028, -0.0028, -0.0028,  ..., -0.0028, -0.0028, -0.0028]])\n"
     ]
    }
   ],
   "source": [
    "print('Initial weights - ', model[0].weight, \"\\n\")\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "images.resize_(64, 784)\n",
    "\n",
    "# Clear the gradients, do this because gradients are accumulated\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# Forward pass, then backward pass, then update weights\n",
    "output = model(images)\n",
    "loss = criterion(output, labels)\n",
    "loss.backward()\n",
    "print('Gradient -', model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated weights -  Parameter containing:\n",
      "tensor([[-0.0164,  0.0232, -0.0242,  ...,  0.0014,  0.0196,  0.0070],\n",
      "        [ 0.0272, -0.0080,  0.0136,  ..., -0.0093, -0.0186,  0.0272],\n",
      "        [-0.0043, -0.0123, -0.0298,  ..., -0.0271,  0.0305,  0.0201],\n",
      "        ...,\n",
      "        [ 0.0031,  0.0065, -0.0122,  ..., -0.0331, -0.0209, -0.0108],\n",
      "        [ 0.0255, -0.0187, -0.0191,  ..., -0.0140, -0.0003,  0.0199],\n",
      "        [ 0.0243,  0.0273,  0.0307,  ...,  0.0254, -0.0233, -0.0005]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Take an update step and display the new weights\n",
    "\n",
    "optimizer.step()\n",
    "print('Updated weights - ', model[0].weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Training Neural Network in Realtime:\n",
    "\n",
    "Now we'll put this algorithm into a loop so we can go through all the images. Some nomenclature, one pass through the entire dataset is called an *epoch*. So here we're going to loop through `trainloader` to get our training batches. For each batch, we'll doing a training pass where we calculate the loss, do a backwards pass, and update the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.0389629404491454\n",
      "Training loss: 0.3890531971129273\n",
      "Training loss: 0.32914855989661296\n",
      "Training loss: 0.2934303085432886\n",
      "Training loss: 0.2655071416563952\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        # Flatten MNIST images into a 784 long vector\n",
    "        images = images.view(images.shape[0], -1)\n",
    "    \n",
    "        # Training pass\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(f\"Training loss: {running_loss/len(trainloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "img = images[0].view(1, 784)\n",
    "plt.imshow(images[0].numpy().squeeze(), cmap='Greys_r')\n",
    "\n",
    "# Turn off gradients to speed up this part\n",
    "with torch.no_grad():\n",
    "    logps = model(img)\n",
    "\n",
    "# Output of the network are log-probabilities, need to take exponential for probabilities\n",
    "ps = torch.exp(logps)\n",
    "ps = ps.data.numpy().squeeze()\n",
    "ps.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 224,
       "width": 423
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
    "ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n",
    "ax1.axis('off')\n",
    "ax2.barh(np.arange(10), ps)\n",
    "ax2.set_aspect(0.1)\n",
    "ax2.set_yticks(np.arange(10))\n",
    "ax2.set_yticklabels(np.arange(10))\n",
    "ax2.set_title('Class Probability')\n",
    "ax2.set_xlim(0, 1.1)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
